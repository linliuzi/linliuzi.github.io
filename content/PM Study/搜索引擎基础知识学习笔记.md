Title: 搜索引擎基础知识学习笔记
Date: 2014-01-05
Category: PM Study
Tags: 技术, 学习笔记
Slug: new_20140105

	虽然我现在做的并非传统的网页搜索，但是搜索引擎的基本思想有大部分是通用的。
	在学习搜索引擎的基础知识的过程中，我果然发现很多熟悉的思想，也算是将自己的经验所得做个知识梳理。
	
**资料链接**
<http://blog.csdn.net/xiaoyu714543065/article/details/7932134>

###基于词频统计——词位置加权的第一代搜索引擎
利用关键词在文档中出现的频率和位置排序是搜索引擎最早期排序的主要思想，其技术发展也最为成熟，是第一阶段搜索引擎的主要排序技术，应用非常广泛，至今仍是许多搜索引擎的核心排序技术。其基本原理是：**关键词在文档中词频越高，出现的位置越重要，则被认为和检索词的相关性越好。**  

**词频统计**  
文档的词频是指查询关键词在文档中出现的频率。查询关键词词频在文档中出现的频率越高，其相关度越大。但当关键词为常用词时，使其对相关性判断的意义非常小。TF/IDF很好的解决了这个问题。TF/IDF算法被认为是信息检索中最重要的发明。  
TF(Term Frequency):单文本词汇频率，用关键词的次数除以网页的总字数，其商称为“关键词的频率”。  
IDF（Inverse Document Frequency）：逆文本频率指数，其原理是，一个关键词在N个网页中出现过，那么N越大，此关键词的权重越小，反之亦然。当关键词为常用词时，其权重极小，从而解决词频统计的缺陷。

**词位置加权**  
在搜索引擎中，主要针对网页进行词位置加权。所以，页面版式信息的分析至关重要。通过对检索关键词在Web页面中不同位置和版式，给予不同的权值，从而根据权值来确定所搜索结果与检索关键词相关程度。  
可以考虑的版式信息有：是否是标题，是否为关键词，是否是正文，字体大小，是否加粗等等。同时，锚文本的信息也是非常重要的，它一般能精确的描述所指向的页面的内容。

###基于链接分析排序的第二代搜索引擎
链接分析排序的思想起源于文献引文索引机制，即论文被引用的次数越多或被越权威的论文引用，其论文就越有价值。链接分析排序的思路与其相似，**网页被别的网页引用的次数越多或被越权威的网页引用，其价值就越大**。被别的网页引用的次数越多，说明该网页越受欢迎，被越权威的网页引用，说明该网页质量越高。  
链接分析排序算法大体可以分为以下几类：基于随机漫游模型的，比如PageRank和Repution算法；基于概率模型的，如SALSA、PHITS；基于Hub和Authority相互加强模型的，如HITS及其变种；基于贝叶斯模型的，如贝叶斯算法及其简化版本。所有的算法在实际应用中都结合传统的内容分析技术进行了优化。

**PageRank算法**  
其基本思想是：页面的重要程度用PageRank值来衡量，PageRank值主要体现在两个方面：引用该页面的页面个数和引用该页面的页面重要程度。  
PageRank是一个与查询无关的静态算法，因此所有网页的PageRank值均可以通过离线计算获得。这样，减少了用户检索时需要的排序时间，极大地降低了查询响应时间。但是PageRank存在两个缺陷：首先PageRank算法严重歧视新加入的网页，因为新的网页的出链接和入链接通常都很少，PageRank值非常低。另外PageRank算法仅仅依靠外部链接数量和重要度来进行排名，而忽略了页面的主题相关性，以至于一些主题不相关的网页（如广告页面）获得较大的PageRank值，从而影响了搜索结果的准确性。

**Topic-Sensitive PageRank算法**  
主题敏感（Topic-Sensitive）的PageRank算法解决了“主题漂流”问题。该算法考虑到有些页面在某些领域被认为是重要的，但并不表示它在其它领域也是重要的。  
网页A链接网页B，可以看作网页A对网页B的评分，如果网页A与网页B属于相同主题，则可认为A对B的评分更可靠。因为A与B可形象的看作是同行，同行对同行的了解往往比不是同行的要多，所以同行的评分往往比不是同行的评分可靠。遗憾的是TSPR并没有利用主题的相关性来提高链接得分的准确性。

**HillTop算法**  
HillTop是一种查询相关性链接分析算法，克服了的PageRank的查询无关性的缺点。HillTop算法认为具有相同主题的相关文档链接对于搜索者会有更大的价值。在Hilltop中仅考虑那些用于引导人们浏览资源的专家页面（Export Sources）。Hilltop在收到一个查询请求时，首先根据查询的主题计算出一列相关性最强的专家页面，然后根据指向目标页面的非从属专家页面的数量和相关性来对目标页面进行排序。  
HillTop算法确定网页与搜索关键词的匹配程度的基本排序过程取代了过分依靠PageRank的值去寻找那些权威页面的方法，避免了许多想通过增加许多无效链接来提高网页PageRank值的作弊方法。HillTop算法通过不同等级的评分确保了评价结果对关键词的相关性，通过不同位置的评分确保了主题（行业）的相关性，通过可区分短语数防止了关键词的堆砌。  
但是，专家页面的搜索和确定对算法起关键作用，专家页面的质量对算法的准确性起着决定性作用，也就忽略了大多数非专家页面的影响。专家页面在互联网中占的比例非常低（1.79%），无法代表互联网全部网页，所以HillTop存在一定的局限性。同时，不同于PageRank算法，HillTop算法的运算是在线运行的，对系统的响应时间产生极大的压力。  

**HITS**
HITS（Hyperlink Induced Topic Search）算法按照超链接的方向，将网页分成两种类型的页面：Authority页面和Hub页面。Authority页面又称权威页面，是指与某个查询关键词和组合最相近的页面，Hub页面又称目录页，该页面的内容主要是大量指向Authority页面的链接，它的主要功能就是把这些Authority页面联合在一起。对于Authority页面P，当指向P的Hub页面越多，质量越高，P的Authority值就越大；而对于Hub页面H，当H指向的Authority的页面越多，Authority页面质量越高，H的Hub值就越大。对整个Web集合而言，Authority和Hub是相互依赖、相互促进，相互加强的关系。Authority和Hub之间相互优化的关系，即为HITS算法的基础。  
HITS基本思想是：算法根据一个网页的入度（指向此网页的超链接）和出度（从此网页指向别的网页）来衡量网页的重要性。在限定范围之后根据网页的出度和入度建立一个矩阵，通过矩阵的迭代运算和定义收敛的阈值不断对两个向量Authority和Hub值进行更新直至收敛。  
实验数据表明，HITS的排名准确性要比PageRank高，HITS算法的设计符合网络用户评价网络资源质量的普遍标准，因此能够为用户更好的利用网络信息检索工具访问互联网资源带来便利。  
但却存在以下缺陷：首先，HITS算法只计算主特征向量，处理不好主题漂移问题；其次，进行窄主题查询时，可能产生主题泛化问题；第三，HITS算法可以说一种实验性质的尝试。它必须在网络信息检索系统进行面向内容的检索操作之后，基于内容检索的结果页面及其直接相连的页面之间的链接关系进行计算。尽管有人尝试通过算法改进和专门设立链接结构计算服务器（Connectivity Server）等操作，可以实现一定程度的在线实时计算，但其计算代价仍然是不可接受的。  

###基于智能化排序的第三代搜索引擎
排序算法在搜索引擎中具有特别重要的地位，目前许多搜索引擎都在进一步研究新的排序方法，来提升用户的满意度。但目前第二代搜索引擎有着以下两个不足之处，在此背景下，基于智能化排序的第三代搜索引擎也就应运而生。  

**相关性问题**  
相关性是指检索词和页面的相关程度。由于语言复杂，仅仅通过链接分析及网页的表面特征来判断检索词与页面的相关性是片面的。例如：检索“稻瘟病”，有网页是介绍水稻病虫害信息的，但文中没有“稻瘟病”这个词，搜索引擎根本无法检索到。正是以上原因，造成大量的搜索引擎作弊现象无法解决。**解决相关性的的方法应该是增加语意理解**，分析检索关键词与网页的相关程度，相关性分析越精准，用户的搜索效果就会越好。同时，相关性低的网页可以剔除，有效地防止搜索引擎作弊现象。检索关键词和网页的相关性是在线运行的，会给系统相应时间很大的压力，可以采用分布式体系结构可以提高系统规模和性能。  

**搜索结果的单一化问题**  
在搜索引擎上，任何人搜索同一个词的结果都是一样。这并不能满足用户的需求。不同的用户对检索的结果要求是不一样的。例如：普通的农民检索“稻瘟病”，只是想得到稻瘟病的相关信息以及防治方法，但农业专家或科技工作者可能会想得到稻瘟病相关的论文。  
解决搜索结果单一的方法是提供个性化服务，实现智能搜索。通过Web数据挖掘，建立用户模型（如用户背景、兴趣、行为、风格），提供个性化服务。  
